{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70ebf36-7a1f-4fc6-b9d4-982bc7304fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import pickle as pkl\n",
    "import parallel\n",
    "import matplotlib.pyplot as plt\n",
    "from dbn.models import SupervisedDBNRegression\n",
    "from elm.elm import Model as elm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.base import clone\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from multiprocessing import Pool\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import pmdarima as pm\n",
    "from dm_test.dm_test import dm_test as dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50d7981-800c-42f9-9f28-2406911efcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\"amz\", \"APPLE\", \"electricity\", \"goldman\", \"msft\", \"pollutions\", \"star\", \"sunspot\", \"vehicle\", \"wine\"]\n",
    "file_prefix = \"dataset/\"\n",
    "file_suffix = \".txt\"\n",
    "models = [\n",
    "          {'model_name': \"SVR\", 'windows': True, 'lags': 20, 'normalize_before_metrics': True, 'differencing_order': 'ADF', 'level': '5%', 'p_level': 0.05},\n",
    "          {'model_name': \"GB\", 'windows': True, 'lags': 20, 'normalize_before_metrics': True, 'differencing_order': 'ADF', 'level': '5%', 'p_level': 0.05},\n",
    "          {'model_name': \"RF\", 'windows': True, 'lags': 20, 'normalize_before_metrics': True, 'differencing_order': 'ADF', 'level': '5%', 'p_level': 0.05},\n",
    "          {'model_name': \"ARIMA\", 'windows': False, 'lags': 20, 'normalize_before_metrics': True, 'differencing_order': 'ADF', 'level': '5%', 'p_level': 0.05},\n",
    "          {'model_name': \"DBN\", 'windows': True, 'lags': 20, 'normalize_before_metrics': True, 'differencing_order': 'ADF', 'level': '5%', 'p_level': 0.05},\n",
    "          {'model_name': \"MLP\", 'windows': True, 'lags': 20, 'normalize_before_metrics': True, 'differencing_order': 'ADF', 'level': '5%', 'p_level': 0.05},\n",
    "          {'model_name': \"ELM\", 'windows': True, 'lags': 20, 'normalize_before_metrics': True, 'differencing_order': 'ADF', 'level': '5%', 'p_level': 0.05},\n",
    "         ]\n",
    "\n",
    "#431\n",
    "random_seed = 5412\n",
    "execution = \"dsnaw\" # \"oracle\" or \"dsnaw\"\n",
    "load_saved_model_results = True\n",
    "save_model_results = True\n",
    "n_mode = \"dynamic\" # \"static\" or \"dynamic\" \n",
    "plot_curves = False\n",
    "train_proportion = 1/2\n",
    "val_proportion = 1/4\n",
    "max_k = 20\n",
    "max_n = len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1163a523-71f1-471d-bee0-d5bf102fc875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read files\n",
    "def read_file(path):\n",
    "    array_ts = np.loadtxt(path)\n",
    "    df = pd.DataFrame(data = array_ts, columns = ['y'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0adb11be-a3f9-4917-bd78-d714d43378be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define split points\n",
    "\n",
    "def define_split_points(df, train, val):\n",
    "    val_index = int(df.shape[0]*train)\n",
    "    test_index = int(df.shape[0]*(train+val))\n",
    "\n",
    "    # fig, ax=plt.subplots(figsize=(9, 4))\n",
    "    # df['y'].loc[:val_index-1].plot(ax=ax, label = 'train')\n",
    "    # df['y'].loc[val_index:test_index-1].plot(ax=ax, label = 'validation')\n",
    "    # df['y'].loc[test_index:].plot(ax=ax, label = 'test')\n",
    "    # ax.legend()\n",
    "    \n",
    "    return val_index, test_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e08b8bd-b936-444c-8567-ee3ab4c17c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#difference time series\n",
    "\n",
    "def check_ADF(ts, lvl, p_lvl):\n",
    "    result = adfuller(ts)\n",
    "    return result[0] < result[4][lvl] and result[1] < p_lvl\n",
    "\n",
    "def difference(df, differencing_order, level, p_level):\n",
    "\n",
    "    df_differenced = None\n",
    "    if differencing_order:    \n",
    "        df_differenced = df.copy()\n",
    "\n",
    "        if differencing_order == 'ADF':\n",
    "            stationary = check_ADF(df_differenced['y'].values, level, p_level)\n",
    "            d = 0\n",
    "            while not stationary:\n",
    "                df_differenced = df_differenced.diff().dropna()\n",
    "                d += 1\n",
    "                stationary = check_ADF(df_differenced['y'].values, level, p_level)\n",
    "            if d == 0:\n",
    "                df_differenced = None\n",
    "            differencing_order = d\n",
    "        else:\n",
    "            i = 0\n",
    "            while i < differencing_order:\n",
    "                df_differenced = df_differenced.diff().dropna()\n",
    "                i+=1\n",
    "                \n",
    "    print(\"d: \", differencing_order)\n",
    "    # if differencing_order:\n",
    "    #     fig, ax=plt.subplots(figsize=(9, 4))\n",
    "    #     df_differenced.y.plot(ax = ax)\n",
    "        \n",
    "    return df_differenced, differencing_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a7b31b5-b50d-4a72-b52d-4439d7a1999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize time series\n",
    "\n",
    "def normalize(df, val_index, d):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    min_max_scaler.fit(df['y'].loc[:val_index-1].values.reshape(-1,1))\n",
    "    df_normalized = pd.DataFrame({'y': np.append(np.zeros(d),min_max_scaler.transform(df['y'].values.reshape(-1, 1)).flatten())}).iloc[d:]\n",
    "    \n",
    "    return df_normalized, min_max_scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b32bff-2b57-4892-9b29-72df0041822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create windows\n",
    "\n",
    "def create_windows(df, lags):\n",
    "    df_windowed = df.copy()\n",
    "    df_windowed['x'] = df_windowed['y'].shift()\n",
    "    for i in range(1, lags):\n",
    "        df_windowed[f'x-{i}'] = df_windowed['x'].shift(i)\n",
    "    df_windowed = df_windowed.dropna()\n",
    "    return df_windowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19bbf07b-bb72-4460-b336-a6f60f16f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridsearch\n",
    "\n",
    "def parallel_gridsearch(estimator, param_grid, x_train, y_train, x_val, y_val):\n",
    "    pool = Pool()\n",
    "    list_params = list(ParameterGrid(param_grid))\n",
    "    results = list(tqdm(pool.imap(partial(parallel.validate_params, estimator=estimator, x_train=x_train, \n",
    "                               y_train=y_train, x_val=x_val, y_val=y_val), list_params), total=len(list_params)))\n",
    "    idx = np.argmin([r[1] for r in results])\n",
    "    best_params = results[idx][0]\n",
    "    best_rmse = results[idx][1]\n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print('Best params: ', best_params)\n",
    "    print('Best rmse: ', best_rmse)\n",
    "    return best_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96b98610-d9d3-43cc-96a2-b57da9ee947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVR\n",
    "\n",
    "def svr_model(lags):\n",
    "    parameters = {'C':[1, 10, 100, 1000], 'gamma': [0.001, 0.01, 0.1, 1],\n",
    "                      'kernel':[\"rbf\"],\n",
    "                      'epsilon': [0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
    "                 }\n",
    "\n",
    "    model = SVR(max_iter = 10000)\n",
    "\n",
    "    return model, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cc807a2-50b7-4cce-9425-f141c7d4894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting\n",
    "\n",
    "def gb_model(lags):\n",
    "    parameters = {'n_estimators': [50, 100, 200], \n",
    "                  'max_depth': [5, 10, 15],\n",
    "                  'max_features': [0.6, 0.8, 1],\n",
    "                  'subsample' : [0.6, 0.8, 1],\n",
    "                  'learning_rate': [0.1, 0.3, 0.5],\n",
    "                 }\n",
    "    \n",
    "    model = GradientBoostingRegressor(random_state=random_seed)\n",
    "\n",
    "    return model, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc7d4a98-ed7c-4580-8a39-5de35170d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "\n",
    "def rf_model(lags):\n",
    "    parameters = {'n_estimators': [50, 100, 200], \n",
    "                  'max_depth': [5, 10, 15],\n",
    "                  'max_features': [0.6, 0.8, 1],\n",
    "                 }\n",
    "    \n",
    "    model = RandomForestRegressor(random_state=random_seed)\n",
    "\n",
    "    return model, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdd044f8-9f56-49a1-8180-39b6cda1d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "\n",
    "def mlp_model(lags):\n",
    "    parameters = {'hidden_layer_sizes': [20, 50, 100], \n",
    "                      'max_iter': [1000],\n",
    "                      'tol': [0.001, 0.0001, 0.00001],\n",
    "                 }\n",
    "    \n",
    "    model = MLPRegressor(activation='logistic', solver='lbfgs', random_state=random_seed)\n",
    "    \n",
    "    return model, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8df571af-0c47-4bfb-985e-5ca3f026106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ELM\n",
    "\n",
    "def elm_model(lags):\n",
    "    parameters = {'hidden_dim': [20, 50, 100, 200, 500],  \n",
    "                 }\n",
    "    \n",
    "    model = elm(input_dim=lags)\n",
    "    \n",
    "    return model, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d089bea0-20db-4176-ab84-e075fca15742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep Belief Network\n",
    "\n",
    "def dbn_model(lags):\n",
    "    \n",
    "    model = SupervisedDBNRegression(hidden_layers_structure=[100],\n",
    "                                    learning_rate_rbm=0.01,\n",
    "                                    learning_rate=0.01,\n",
    "                                    n_epochs_rbm=20,\n",
    "                                    n_iter_backprop=200,\n",
    "                                    batch_size=16,\n",
    "                                    activation_function='relu',\n",
    "                                    verbose=False)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b55ea8-811f-49fe-89fa-9955b17be746",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name = {\n",
    "    'SVR': svr_model, \n",
    "    'GB': gb_model,\n",
    "    'RF': rf_model,\n",
    "    'DBN': dbn_model,\n",
    "    'MLP': mlp_model,\n",
    "    'ELM': elm_model,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6816fbd7-8839-4666-9a83-828e9cfabada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def train_model(model_name, df, val_index, test_index, lags):\n",
    "\n",
    "    if model_name == \"ARIMA\":\n",
    "        \n",
    "        model = pm.auto_arima(df['y'].loc[:test_index-1],\n",
    "                          test='adf',       \n",
    "                          max_p=lags, max_q=lags,        \n",
    "                          seasonal=False,   \n",
    "                          trace=True,\n",
    "                          error_action='ignore',  \n",
    "                          suppress_warnings=True, \n",
    "                          stepwise=True)\n",
    "        best_params=model.get_params()\n",
    "        \n",
    "    elif model_name == \"DBN\":\n",
    "        \n",
    "        model = dbn_model(lags)\n",
    "        \n",
    "        x_train = df.drop(columns = ['y']).loc[:test_index-1].values\n",
    "        y_train = df['y'].loc[:test_index-1].values\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        best_params={}\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        model, param_grid = models_name[model_name](lags)\n",
    "\n",
    "        x_train = df.drop(columns = ['y']).loc[:val_index-1].values\n",
    "        y_train = df['y'].loc[:val_index-1].values\n",
    "        x_val = df.drop(columns = ['y']).loc[val_index:test_index-1].values\n",
    "        y_val = df['y'].loc[val_index:test_index-1].values\n",
    "        \n",
    "        \n",
    "        best_params = parallel_gridsearch(model, param_grid, \n",
    "                                    x_train, y_train,\n",
    "                                    x_val, y_val)\n",
    "\n",
    "        model.set_params(**best_params)\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "    \n",
    "    return model, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd4d511f-ca06-4d18-934e-3d06e3e4cc13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test model\n",
    "\n",
    "def test_model(model, model_name, df, test_index, scaler):\n",
    "    if model_name != \"ARIMA\":\n",
    "        y_test = df['y'].loc[test_index:].values\n",
    "        x_test = df.drop(columns = ['y']).loc[test_index:].values\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "    else:\n",
    "        y_test = df['y'].loc[test_index:].values\n",
    "        y_pred = np.zeros(y_test.size)\n",
    "        for i in tqdm(range(y_pred.size)):\n",
    "            y_pred[i] = model.predict(n_periods = 1)\n",
    "            model.update([y_test[i]])\n",
    "\n",
    "    y_pred = scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "    y_test = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "    return y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78ff7ece-000f-4085-8c18-817eb7a6134b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recursive_differencing_coefficients(order):\n",
    "    if order <= 1:\n",
    "        return np.array([1, -1])\n",
    "    else:\n",
    "        prev_coefficients = recursive_differencing_coefficients(order-1)\n",
    "        coefficients = np.zeros(order+1)\n",
    "        coefficients[0] = prev_coefficients[0]\n",
    "        coefficients[-1] = -prev_coefficients[-1]\n",
    "        for i in range(1, order):\n",
    "            coefficients[i] = prev_coefficients[i] - prev_coefficients[i-1]\n",
    "        return coefficients   \n",
    "\n",
    "def inverse_difference(differencing_order, df, df_diff, test_index, y_pred):\n",
    "    df_pred = df.copy()\n",
    "    \n",
    "    for i in range(1, differencing_order + 1):\n",
    "        df_pred[f'y-{i}'] = df_pred['y'].shift(i)\n",
    "    \n",
    "    df_pred['y_diff'] = df_diff['y']\n",
    "    df_pred['y_diff'][test_index:] = y_pred\n",
    "    \n",
    "    df_pred.fillna(0, inplace=True)\n",
    "    \n",
    "    coefficients = recursive_differencing_coefficients(differencing_order)\n",
    "    df_pred['y_pred'] = df_pred['y_diff']\n",
    "    for i in range(1, differencing_order + 1):\n",
    "        df_pred['y_pred'] = df_pred['y_pred'] - coefficients[i]*df_pred[f'y-{i}']\n",
    "        \n",
    "    y_pred = df_pred['y_pred'][test_index:].values    \n",
    "    y_test = df_pred['y'][test_index:].values\n",
    "    \n",
    "    return y_pred, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "142e93db-40fc-4d84-88d3-090af92f5668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot results\n",
    "def plot_results(y_pred, y_test):\n",
    "    fig, ax=plt.subplots(figsize=(9, 4))\n",
    "    plt.plot(y_pred, label = 'predicted')\n",
    "    plt.plot(y_test, label = 'real')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff133909-af3c-4e6d-a8b3-08abf2962289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle(preds, real):\n",
    "    best_pred = np.zeros(real.size)\n",
    "    for i in range(real.size):\n",
    "        candidates = np.array([p[i] for p in preds])\n",
    "        idx = np.argmin(np.absolute(candidates - real[i]))\n",
    "        best_pred[i] = candidates[idx]\n",
    "    return best_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89830e38-9dc7-43da-ad2b-4969f00da99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate metrics\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).reshape(-1)\n",
    "    y_pred = np.asarray(y_pred).reshape(-1)\n",
    "\n",
    "    posi_with_zeros = np.where(y_true == 0)[0]\n",
    "\n",
    "    y_true = [n for k, n in enumerate(y_true) if k not in posi_with_zeros]\n",
    "    y_pred = [n for k, n in enumerate(y_pred) if k not in posi_with_zeros]\n",
    "    \n",
    "    y_true = np.asarray(y_true).reshape(-1)\n",
    "    y_pred = np.asarray(y_pred).reshape(-1)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).reshape(-1)\n",
    "    y_pred = np.asarray(y_pred).reshape(-1)\n",
    "\n",
    "    posi_with_zeros = np.where(y_true == 0)[0]\n",
    "\n",
    "    y_true = [n for k, n in enumerate(y_true) if k not in posi_with_zeros]\n",
    "    y_pred = [n for k, n in enumerate(y_pred) if k not in posi_with_zeros]\n",
    "    \n",
    "    y_true = np.asarray(y_true).reshape(-1)\n",
    "    y_pred = np.asarray(y_pred).reshape(-1)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).reshape(-1)\n",
    "    y_pred = np.asarray(y_pred).reshape(-1)\n",
    "\n",
    "    posi_with_zeros = np.where((np.abs(y_true)+np.abs(y_pred))/2 == 0 )[0]\n",
    "\n",
    "    y_true = [n for k, n in enumerate(y_true) if k not in posi_with_zeros]\n",
    "    y_pred = [n for k, n in enumerate(y_pred) if k not in posi_with_zeros]\n",
    "    \n",
    "    y_true = np.asarray(y_true).reshape(-1)\n",
    "    y_pred = np.asarray(y_pred).reshape(-1)\n",
    "    return np.mean(np.abs(y_true - y_pred) / ((np.abs(y_true)+np.abs(y_pred))/2)) * 100\n",
    "\n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    \n",
    "    y_true = np.asarray(y_true).reshape(-1)\n",
    "    y_pred = np.asarray(y_pred).reshape(-1)\n",
    "\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def average_relative_variance(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true).reshape(-1)\n",
    "    y_pred = np.asarray(y_pred).reshape(-1)\n",
    "    mean = np.mean(y_true)\n",
    "\n",
    "    error_sup = np.square(np.subtract(y_true, y_pred)).sum()\n",
    "    error_inf = np.square(np.subtract(y_pred, mean)).sum()\n",
    "\n",
    "    return error_sup / error_inf\n",
    "\n",
    "def calculate_metrics(y_pred, y_test, normalize_before_metrics, scaler, df):\n",
    "    if normalize_before_metrics:\n",
    "        scaler.fit(df['y'].values.reshape(-1,1))\n",
    "        y_pred = scaler.transform(y_pred.reshape(-1, 1)).flatten()\n",
    "        y_test = scaler.transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    nrmse = rmse/(y_test.max()-y_test.min())\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    smape = symmetric_mean_absolute_percentage_error(y_test, y_pred)\n",
    "    arv = average_relative_variance(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    res = {'MSE': mse, 'MAPE': mape, 'ARV': arv, 'MAE': mae, 'RMSE': rmse, 'NRMSE': nrmse, 'SMAPE': smape}\n",
    "    \n",
    "    # for key, value in res.items():\n",
    "    #     print(f'{key}: {value}')\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05e8b125-721a-460f-8c30-1bd2088ae559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridsearch\n",
    "\n",
    "def parallel_gridsearch_dsnaw(n_mode, df, pred_results, val_index, test_index, param_grid):\n",
    "    pool = Pool()\n",
    "    list_params = list(ParameterGrid(param_grid))\n",
    "    results = list(tqdm(pool.imap(partial(parallel.validate_ds_params, n_mode=n_mode, df=df, pred_results=pred_results, val_index=val_index, test_index=test_index), list_params), total=len(list_params)))\n",
    "    idx = np.argmin([r[1] for r in results])\n",
    "    \n",
    "    best_params = results[idx][0]\n",
    "    best_rmse = results[idx][1]\n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    print('Best params: ', best_params)\n",
    "    print('Best rmse: ', best_rmse)\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e51eb454-65e4-475a-a67a-696774074f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dsnaw(params, df, pred_results, test_index, n_mode):\n",
    "    k = params['k']\n",
    "    comb = params['comb']    \n",
    "    \n",
    "    y_dsnaw = np.zeros(df['y'].size-test_index)\n",
    "    for i in range(test_index, df['y'].size):\n",
    "        rmse_roc = []\n",
    "        real_roc = df['y'].loc[i-k:i-1].values\n",
    "        \n",
    "        roc_list = []\n",
    "        for j in range(0, len(pred_results)):      \n",
    "            pred_roc = pred_results[j]['y'].loc[i-k:i-1].values\n",
    "            roc_list.append(pred_roc)\n",
    "            rmse_roc.append((j, np.sqrt(metrics.mean_squared_error(pred_roc, real_roc))))\n",
    "        sorted_rmse_roc = sorted(rmse_roc, key=lambda x: x[1])\n",
    "        \n",
    "        roc_list_sorted = np.zeros((len(pred_results), k))\n",
    "        for j in range(0, len(pred_results)):\n",
    "            roc_list_sorted[j] = roc_list[sorted_rmse_roc[j][0]]        \n",
    "        roc_list = roc_list_sorted\n",
    "        \n",
    "        if n_mode == \"dynamic\":\n",
    "            Ns = [1, 3, 5]            \n",
    "        else:\n",
    "            Ns = [params['n']]\n",
    "            \n",
    "        n_results = [] \n",
    "        for n in Ns:\n",
    "            comb_roc = np.zeros(roc_list.shape[1])\n",
    "            for j in range(comb_roc.size):\n",
    "                if comb == 'median':\n",
    "                    comb_roc[j] = np.median(roc_list[:n, j])\n",
    "                else:\n",
    "                    comb_roc[j] = np.average(roc_list[:n, j])\n",
    "            n_results.append(np.sqrt(metrics.mean_squared_error(comb_roc, real_roc)))\n",
    "        n = Ns[np.argmin(n_results)]\n",
    "        \n",
    "        comb_values = np.zeros(n)\n",
    "        for j in range(0, n):\n",
    "            comb_values[j] = pred_results[sorted_rmse_roc[j][0]]['y'].loc[i]\n",
    "        if comb == 'median':\n",
    "            y_dsnaw[i-test_index] = np.median(comb_values)\n",
    "        else:\n",
    "            y_dsnaw[i-test_index] = np.average(comb_values)\n",
    "\n",
    "    return y_dsnaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6485de5b-93e2-40b8-afb6-5d3e7eeba5b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(execution, df, model_name, train_proportion, val_proportion, windows, lags, max_k, plot_curves, normalize_before_metrics, differencing_order, level, p_level):\n",
    "    print(\"\\n###############################################\\n\")\n",
    "    print(\"Executing: \", model_name)\n",
    "    val_index, test_index = define_split_points(df, train_proportion, val_proportion)\n",
    "    d = 0\n",
    "    if differencing_order:\n",
    "        df_differenced, d = difference(df, differencing_order, level, p_level)\n",
    "    if(d):\n",
    "        df_normalized, min_max_scaler = normalize(df_differenced, val_index, d)\n",
    "    else:\n",
    "        df_normalized, min_max_scaler = normalize(df, val_index, d)\n",
    "    \n",
    "    if(windows):\n",
    "        df_normalized = create_windows(df_normalized, lags)        \n",
    "\n",
    "    estimator, params = train_model(model_name, df_normalized, val_index, test_index, lags)\n",
    "    if(execution == \"dsnaw\"):\n",
    "        result_index = val_index - max_k\n",
    "    else:\n",
    "        result_index = test_index\n",
    "    y_pred, y_test = test_model(estimator, model_name, df_normalized, result_index, min_max_scaler)\n",
    "    if d:\n",
    "        y_pred, y_test = inverse_difference(d, df, df_differenced, result_index, y_pred)        \n",
    "    if(execution == \"dsnaw\"):\n",
    "        if plot_curves:\n",
    "            plot_results(y_pred[(test_index-result_index):], y_test[(test_index-result_index):])\n",
    "        m = calculate_metrics(y_pred[(test_index-result_index):], y_test[(test_index-result_index):], normalize_before_metrics, min_max_scaler, df)\n",
    "    else:\n",
    "        if plot_curves:\n",
    "            plot_results(y_pred, y_test)\n",
    "        m = calculate_metrics(y_pred, y_test, normalize_before_metrics, min_max_scaler, df)\n",
    "    return y_pred, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d40926b-66b7-47b0-8987-22097e4fa3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series:  amz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:07<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'comb': 'median', 'k': 4}\n",
      "Best rmse:  574.9834621983266\n",
      "Time Series:  APPLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:07<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'comb': 'average', 'k': 7}\n",
      "Best rmse:  815.0117709468019\n",
      "Time Series:  electricity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'comb': 'median', 'k': 11}\n",
      "Best rmse:  6844.247451319562\n",
      "Time Series:  goldman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:03<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'comb': 'average', 'k': 6}\n",
      "Best rmse:  2.9459534638279607\n",
      "Time Series:  msft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:03<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'comb': 'median', 'k': 2}\n",
      "Best rmse:  0.3995879193395037\n",
      "Time Series:  pollutions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 21.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'comb': 'median', 'k': 1}\n",
      "Best rmse:  489.8684370067853\n",
      "Time Series:  star\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:03<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'comb': 'median', 'k': 14}\n",
      "Best rmse:  0.20990193607341262\n",
      "Time Series:  sunspot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 17.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'comb': 'median', 'k': 20}\n",
      "Best rmse:  12.072038624611512\n",
      "Time Series:  vehicle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 18.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'comb': 'median', 'k': 7}\n",
      "Best rmse:  0.8591232125749121\n",
      "Time Series:  wine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:01<00:00, 20.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'comb': 'average', 'k': 20}\n",
      "Best rmse:  20.390818143265804\n"
     ]
    }
   ],
   "source": [
    "metric_res = []\n",
    "params_res = []\n",
    "value_res = {}\n",
    "\n",
    "\n",
    "for f in file_names:\n",
    "    print(\"Time Series: \", f)\n",
    "    df = read_file(file_prefix + f + file_suffix)\n",
    "    \n",
    "    results = []\n",
    "    m_results = []\n",
    "\n",
    "    if load_saved_model_results:\n",
    "        with open('results_pkl/models_results/' + f + '.pkl', 'rb') as handle:\n",
    "            results, m_results = pkl.load(handle)\n",
    "    \n",
    "    else:\n",
    "\n",
    "        for args in models:\n",
    "            run_result = run_model(execution=execution, df=df, train_proportion=train_proportion, val_proportion=val_proportion, plot_curves=plot_curves, max_k = max_k, **args)\n",
    "            results.append((args['model_name'], run_result[0]))\n",
    "            m_results.append((args['model_name'], run_result[1]))\n",
    "        \n",
    "        if save_model_results:\n",
    "            with open('results_pkl/models_results/' + f + '.pkl', 'wb') as handle:\n",
    "                pkl.dump((results, m_results), handle)\n",
    "\n",
    "    val_index, test_index = define_split_points(df, train_proportion, val_proportion)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    real = df['y'].loc[test_index:].values\n",
    "\n",
    "    if (execution == \"oracle\"):\n",
    "        oracle_pred = oracle([r[1] for r in results], real)\n",
    "        m = calculate_metrics(oracle_pred, real, True, min_max_scaler, df)\n",
    "        metric_res.append((f, m))\n",
    "\n",
    "    else:\n",
    "        \n",
    "        pred_results = []\n",
    "        v_results = {}\n",
    "        \n",
    "        \n",
    "        min_max_scaler.fit(df['y'].values.reshape(-1,1))\n",
    "        \n",
    "        for r in results:\n",
    "            temp = pd.DataFrame(data = np.zeros(df['y'].size), columns = ['y'])\n",
    "            temp['y'][val_index - max_k:] = r[1]\n",
    "            pred_results.append(temp)\n",
    "            \n",
    "            v_results[r[0]] = min_max_scaler.transform(r[1][-(df['y'].size-test_index):].reshape(-1, 1)).flatten() \n",
    "        v_results['Real'] = min_max_scaler.transform(df['y'].loc[test_index:].values.reshape(-1, 1)).flatten() \n",
    "        \n",
    "        parameters = {\n",
    "            'k': list(range(1,max_k +1)),\n",
    "            'comb': ['median', 'average'],\n",
    "        }\n",
    "        if n_mode == \"static\":\n",
    "            parameters['n'] = list(range(1,max_n +1))\n",
    "            \n",
    "        grid = list(ParameterGrid(parameters))\n",
    "        best_params = parallel_gridsearch_dsnaw(n_mode, df, pred_results, val_index, test_index, parameters)\n",
    "        params_res.append((f, best_params))\n",
    "                \n",
    "        y_dsnaw = test_dsnaw(best_params, df, pred_results, test_index, n_mode)\n",
    "        m = calculate_metrics(y_dsnaw, real, True, min_max_scaler, df)\n",
    "        m_results.append((\"Proposed\", m))\n",
    "        metric_res.append((f, m_results))\n",
    "        v_results['Proposed'] = min_max_scaler.transform(y_dsnaw.reshape(-1, 1)).flatten() \n",
    "        value_res[f] = v_results\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1df2e880-99ac-4e3e-8f84-1764f7384b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution == \"dsnaw\":\n",
    "    dict_results = {'metric': metric_res, 'params': params_res, 'value': value_res}\n",
    "    if n_mode == \"dynamic\":\n",
    "        dy_str = \"_dynamic_n\"\n",
    "    else:\n",
    "        dy_str = \"\"\n",
    "    with open('results_pkl/proposed' + dy_str + '.pkl', 'wb') as handle:\n",
    "            pkl.dump(dict_results, handle)\n",
    "elif execution == \"oracle\":\n",
    "    with open('results_pkl/oracle.pkl', 'wb') as handle:\n",
    "            pkl.dump(metric_res, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f22158-ab45-4667-8d94-66792cb7c7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
